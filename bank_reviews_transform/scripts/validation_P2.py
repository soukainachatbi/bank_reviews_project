import pandas as pd
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import seaborn as sns

load_dotenv()

def comprehensive_validation():
    """Validation compl√®te de la Phase 2"""
    
    DB_URL = f"postgresql+psycopg2://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
    engine = create_engine(DB_URL)
    
    print("üîç VALIDATION COMPL√àTE DE LA PHASE 2")
    print("=" * 50)
    
    # 1. V√©rification du nettoyage des donn√©es
    print("\n1Ô∏è‚É£ NETTOYAGE DES DONN√âES")
    print("-" * 30)
    
    # Compter les doublons √©limin√©s
    original_count = pd.read_sql("SELECT COUNT(*) as count FROM staging_reviews", engine).iloc[0]['count']
    cleaned_count = pd.read_sql("SELECT COUNT(*) as count FROM stg_reviews", engine).iloc[0]['count']
    
    print(f"üìä Avis originaux: {original_count}")
    print(f"üìä Avis apr√®s nettoyage: {cleaned_count}")
    print(f"üìä Doublons supprim√©s: {original_count - cleaned_count} ({((original_count - cleaned_count)/original_count*100):.1f}%)")
    
    # V√©rifier la qualit√© du texte
    text_quality = pd.read_sql("""
        SELECT 
            text_quality,
            COUNT(*) as count,
            ROUND(AVG(text_length)::numeric, 0) as avg_length
        FROM stg_reviews 
        GROUP BY text_quality
    """, engine)
    print(f"\nüìù Distribution qualit√© du texte:")
    print(text_quality.to_string(index=False))
    
    # 2. V√©rification de l'analyse de sentiment
    print("\n\n2Ô∏è‚É£ ANALYSE DE SENTIMENT")
    print("-" * 30)
    
    sentiment_stats = pd.read_sql("""
        SELECT 
            sentiment,
            COUNT(*) as count,
            ROUND(AVG(rating)::numeric, 2) as avg_rating,
            ROUND(AVG(confidence)::numeric, 3) as avg_confidence
        FROM reviews_enriched 
        WHERE sentiment IS NOT NULL
        GROUP BY sentiment
        ORDER BY count DESC
    """, engine)
    print(f"üìä Distribution des sentiments:")
    print(sentiment_stats.to_string(index=False))
    
    # Coh√©rence sentiment/rating
    consistency = pd.read_sql("""
        SELECT 
            sentiment_rating_consistency,
            COUNT(*) as count,
            ROUND((COUNT(*) * 100.0 / SUM(COUNT(*)) OVER())::numeric, 1) as percentage
        FROM reviews_enriched 
        WHERE sentiment IS NOT NULL
        GROUP BY sentiment_rating_consistency
    """, engine)
    print(f"\nüéØ Coh√©rence sentiment/note:")
    print(consistency.to_string(index=False))
    
    # 3. V√©rification de l'extraction de langues
    print("\n\n3Ô∏è‚É£ D√âTECTION DE LANGUES")
    print("-" * 30)
    
    language_stats = pd.read_sql("""
        SELECT 
            detected_language,
            COUNT(*) as count,
            ROUND((COUNT(*) * 100.0 / SUM(COUNT(*)) OVER())::numeric, 1) as percentage
        FROM stg_reviews 
        GROUP BY detected_language
        ORDER BY count DESC
    """, engine)
    print(f"üåç Distribution des langues:")
    print(language_stats.to_string(index=False))
    
    # 4. V√©rification de l'analyse de topics
    print("\n\n4Ô∏è‚É£ ANALYSE DE TOPICS")
    print("-" * 30)
    
    try:
        topic_stats = pd.read_sql("""
            SELECT 
                topic_category,
                COUNT(*) as count,
                ROUND(AVG(topic_confidence)::numeric, 3) as avg_confidence,
                STRING_AGG(DISTINCT LEFT(topic_keywords, 50), ' | ') as sample_keywords
            FROM reviews_enriched 
            WHERE topic_category IS NOT NULL
            GROUP BY topic_category
            ORDER BY count DESC
        """, engine)
        print(f"üè∑Ô∏è  Distribution des cat√©gories de topics:")
        print(topic_stats.to_string(index=False))
        
        # Topics par sentiment
        topic_sentiment = pd.read_sql("""
            SELECT 
                topic_category,
                sentiment,
                COUNT(*) as count
            FROM reviews_enriched 
            WHERE topic_category IS NOT NULL AND sentiment IS NOT NULL
            GROUP BY topic_category, sentiment
            ORDER BY topic_category, sentiment
        """, engine)
        print(f"\nüîó Topics par sentiment:")
        pivot_table = topic_sentiment.pivot(index='topic_category', columns='sentiment', values='count').fillna(0)
        print(pivot_table.to_string())
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Analyse de topics non disponible: {e}")
    
    # 5. V√©rification par banque
    print("\n\n5Ô∏è‚É£ ANALYSE PAR BANQUE")
    print("-" * 30)
    
    bank_stats = pd.read_sql("""
        SELECT 
            bank,
            COUNT(*) as total_reviews,
            ROUND(AVG(rating)::numeric, 2) as avg_rating,
            COUNT(CASE WHEN sentiment = 'positive' THEN 1 END) as positive_reviews,
            COUNT(CASE WHEN sentiment = 'negative' THEN 1 END) as negative_reviews
        FROM reviews_enriched 
        WHERE sentiment IS NOT NULL
        GROUP BY bank
        ORDER BY total_reviews DESC
    """, engine)
    print(f"üè¶ Statistiques par banque:")
    print(bank_stats.to_string(index=False))
    
    # 6. M√©triques de qualit√© globales
    print("\n\n6Ô∏è‚É£ M√âTRIQUES DE QUALIT√â")
    print("-" * 30)
    
    quality_metrics = pd.read_sql("""
        SELECT 
            COUNT(*) as total_reviews,
            COUNT(CASE WHEN sentiment IS NOT NULL THEN 1 END) as with_sentiment,
            COUNT(CASE WHEN topic_category IS NOT NULL THEN 1 END) as with_topics,
            COUNT(CASE WHEN detected_language != 'unknown' THEN 1 END) as with_language,
            ROUND(AVG(CASE WHEN confidence IS NOT NULL THEN confidence END)::numeric, 3) as avg_sentiment_confidence,
            COUNT(CASE WHEN review_quality = 'high' THEN 1 END) as high_quality,
            COUNT(CASE WHEN sentiment_rating_consistency = 'coherent' THEN 1 END) as coherent_reviews
        FROM reviews_enriched
    """, engine)
    
    metrics = quality_metrics.iloc[0]
    total = metrics['total_reviews']
    
    print(f"üìä Total des avis trait√©s: {total}")
    print(f"üìä Avec analyse de sentiment: {metrics['with_sentiment']} ({metrics['with_sentiment']/total*100:.1f}%)")
    print(f"üìä Avec extraction de topics: {metrics['with_topics']} ({metrics['with_topics']/total*100:.1f}%)")
    print(f"üìä Avec d√©tection de langue: {metrics['with_language']} ({metrics['with_language']/total*100:.1f}%)")
    print(f"üìä Confiance sentiment moyenne: {metrics['avg_sentiment_confidence']}")
    print(f"üìä Avis haute qualit√©: {metrics['high_quality']} ({metrics['high_quality']/total*100:.1f}%)")
    print(f"üìä Avis coh√©rents: {metrics['coherent_reviews']} ({metrics['coherent_reviews']/total*100:.1f}%)")
    
    # 7. Recommandations
    print("\n\n7Ô∏è‚É£ RECOMMANDATIONS")
    print("-" * 30)
    
    # Taux de couverture
    sentiment_coverage = metrics['with_sentiment'] / total
    topic_coverage = metrics['with_topics'] / total
    coherence_rate = metrics['coherent_reviews'] / total
    
    if sentiment_coverage < 0.9:
        print("‚ö†Ô∏è  Couverture sentiment faible - v√©rifier la configuration VADER/TextBlob")
    
    if topic_coverage < 0.7:
        print("‚ö†Ô∏è  Couverture topics faible - ajuster les param√®tres LDA")
    
    if coherence_rate < 0.7:
        print("‚ö†Ô∏è  Coh√©rence sentiment/note faible - v√©rifier la qualit√© des donn√©es")
    
    if metrics['avg_sentiment_confidence'] and metrics['avg_sentiment_confidence'] < 0.3:
        print("‚ö†Ô∏è  Confiance sentiment faible - revoir les seuils de classification")
    
    print(f"\n‚úÖ PHASE 2 TERMIN√âE AVEC SUCC√àS")
    print(f"üìà Donn√©es pr√™tes pour la Phase 3 (Mod√©lisation en √©toile)")
    
    return {
        'total_reviews': total,
        'sentiment_coverage': sentiment_coverage,
        'topic_coverage': topic_coverage,
        'coherence_rate': coherence_rate,
        'avg_confidence': metrics['avg_sentiment_confidence']
    }

if __name__ == "__main__":
    results = comprehensive_validation()